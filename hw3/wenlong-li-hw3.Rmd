---
title: "CS 422"
output: 
  html_notebook:
    toc: yes
    toc_float: yes
author: Wenlong Li
---

### Part 2.1
```{r}
library("ISLR")
options(digits=2)
setwd("./")
set.seed(1122)
index <- sample(1:nrow(Auto), 0.95*dim(Auto)[1])
train.df <- Auto[index,]
test.df <- Auto[-index,]
print(test.df)
```
### Part 2.1-a
### Part 2.1-a-i
#### name is a string type and cannot be used directly, and name and mpg are basically irrelevant
### Part 2.1-a-ii

```{r}
library(dplyr)
library(modelr)
data <- select(train.df, -name)
model <- lm(mpg = ~ ., data = data)
summary(model)
rmse = rmse(model = model, data = data)
str <- paste0("R-squared: 0.817 ","RSE: 3.4 ","RMSE: ",round(rmse, digits = 2))
print(str)
```
#### R2 = 0.817,RSE = 3.4,RMSE = 3.33, There is still a certain distance from the data fitting degree to perfection.
### Part 2.1-a-iii
```{r}
plot(model, 1)
```
### Part 2.1-a-iv
```{r}
hist(model$residuals, main = "Advertising Residual Histogram", xlab = "Model Residuals", density = 10, angle = 45, col = "red",
border = "blue", labels=T,  ylim=c(0,100))
```
#### the histogram follow a Gaussian distribution,Looks reasonably good as residuals appear homosceadastic and clustered around 0. (Though they don’t appear to be normally distributed.)

### Part 2.1-b
### Part 2.1-b-i
#### weight year and origin are statistically significant,cylinders displacement horsepower and acceleration are not statistically significant

```{r}
library(dplyr)
library(modelr)
new.data <- select(train.df, mpg, weight, year, origin)
new.model <- lm(mpg = ~ ., data = new.data)
```
### Part 2.1-b-ii
```{r}
summary(new.model)
rmse = rmse(model = new.model, data = new.data)
str <- paste0("R-squared: 0.813 ","RSE: 3.4 ","RMSE: ",round(rmse, digits = 2))
print(str)
```
### Part 2.1-b-iii
```{r}
plot(new.model, 1)
```

### Part 2.1-b-iv
```{r}
hist(new.model$residuals, main = "Advertising Residual Histogram", xlab = "Model Residuals", density = 10, angle = 45, col = "red",
border = "blue", labels=T,  ylim=c(0,110))
```
#### the histogram follow a Gaussian distribution,Looks reasonably good as residuals appear homosceadastic and clustered around 0. (Though they don’t appear to be normally distributed.)

### Part 2.1-b-v
#### The two models are basically the same, because the statistically insignificant predictors are removed, and the final effect of the model is not much affected.

### Part 2.1-c
```{r}
res <- predict(new.model, newdata=test.df, interval = "confidence", level = 0.95)
new.df = data.frame(res[,1:1], test.df$mpg)
names(new.df)[names(new.df) == 'res...1.1.'] <- 'Prediction'
names(new.df)[names(new.df) == 'test.df.mpg'] <- 'Response'
print(new.df)
```
### Part 2.1-d
```{r}
new.df["Matches"] = 0
i <- 0
ret <- apply(new.df, 1, function(x){
  print(i)
  i++
  print(round(x, digits = 2))
})

print(t(ret))
```




