---
title: "CS 422"
output: 
  html_notebook:
    toc: yes
    toc_float: yes
author: Wenlong Li
---

### Part 2.1-a
```{r}
library("dplyr")
setwd("./")
df <- read.csv("hotel_bookings.csv", sep = ',',header = T)
df %>% group_by(hotel) %>% summarise(count = n())

```
### Part 2.1-b
```{r}
canceled.num <- filter(df, df$is_canceled == 1) %>% nrow()
not.canceled.num <- filter(df, df$is_canceled == 0) %>% nrow()
cat("Number of guests who canceled reservation: ",canceled.num)
cat("\nNumber of guests who did not cancel the reservation: ",not.canceled.num)
```
### Part 2.1-c
```{r}
table <- filter(df, df$is_canceled == 0) %>% group_by(customer_type) %>% summarise(count = n())
index <- which.max(unlist(table["count"]))
ret <- table[index,]
str <- paste("Customer type with the most reservations is",ret["customer_type"], ", with" ,ret["count"],"reservations")
print(str)
```
### Part 2.1-d
```{r}
library("dplyr")
ret <- filter(df, df$is_canceled == 0) %>% select(required_car_parking_spaces) %>% colSums(na.rm = TRUE)
parking.num = ret["required_car_parking_spaces"]
str <- paste(not.canceled.num,"customers required the most number of parking spaces",parking.num)
print(str)
```
### Part 2.1-e
```{r}
library("dplyr")

repeat.all <- filter(df, df$is_canceled == 0) %>% select(previous_bookings_not_canceled) %>% colSums(na.rm = TRUE)

repeat.parking <- filter(df, df$is_canceled == 0, df$required_car_parking_spaces>0) %>% select(previous_bookings_not_canceled) %>% colSums(na.rm = TRUE)

str <- paste(not.canceled.num-repeat.all["previous_bookings_not_canceled"],"customers required the least number of parking spaces",parking.num-repeat.parking["previous_bookings_not_canceled"])
print(str)
```
### Part 2.1-f
```{r}
row.num <-filter(df, df$reserved_room_type == df$assigned_room_type) %>% nrow()
print(row.num)
ret <-row.num * 100.0/nrow(df)
print(paste(round(ret,2),"% of the people who expressed a room preference during reservation got the room during check-in."))
```
### Part 2.1-g
```{r}
h1.df<-filter(df,df$hotel == "City Hotel") %>% group_by(country) %>% summarise(count = n())
h1.df = h1.df[order(h1.df$count, decreasing=TRUE),]
barplot(rev(h1.df[0:10,]$count), names.arg = rev(h1.df[0:10,]$country), xlim = c(0, 12), main="Top 10 countries of origin for City Hotel", col =rainbow(10)) 

h2.df<-filter(df,df$hotel == "Resort Hotel") %>% group_by(country) %>% summarise(count = n())
h2.df = h2.df[order(h2.df$count, decreasing=TRUE),]
h2.df = h2.df[-10,]
barplot(rev(h2.df[0:10,]$count), names.arg = rev(h2.df[0:10,]$country), xlim = c(0, 12), main="Top 10 countries of origin for Resort Hotel", col = rainbow(10)) 
```
### Part 2.1-h
### Part 2.1-h-i
```{r}
print("the most visitors to either type of the hotels arrive from a specific country is PRT")
```

### Part 2.1-h-ii
#### No matter which country, there are more people who like City Hotal.

### Part 2.2
```{r}
set.seed(1122)
index <- sample(1:nrow(df), 0.9*dim(df)[1])
train.df <- df[index,]
test.df <- df[-index,]
```
### Part 2.2-a
```{r}
library(rpart)
model <- rpart(is_canceled ~ ., data = select(train.df, -reservation_status, -country, -agent, -company, -reservation_status_date), method = "class")
#summary(model)
```
### Part 2.2-a-i
```{r}
library(rpart.plot)
rpart.plot(model, extra=104, fallen.leaves=T, type=4, main="Hotal Dataset Decision Tree")
```
### Part 2.2-a-ii
#### deposit_type total_of_special_requests previous_cancellations lead_time  market_segment    customer_type distribution_channel adr required_car_parking_spaces 
                           
### Part 2.2-a-iii
```{r}
library(caret)
pred <- predict(model, test.df, type = "class")
cmx<-confusionMatrix(pred, as.factor(test.df$is_canceled), positive='1')
cat("Before pruning:\n  Accuracy:",round(as.double(cmx$overall["Accuracy"]),3),"\n  Error:",round(1-as.double(cmx$overall["Accuracy"]),3),"\n  Balanced Accuracy:",round(as.double(cmx$byClass["Balanced Accuracy"]),3),"\n  Specificity:",round(as.double(cmx$byClass["Specificity"]),3),"\n  Sensitivity:",round(as.double(cmx$byClass["Sensitivity"]),3),"\n  Precision:",round(as.double(cmx$byClass["Pos Pred Value"]),3))
```
### Part 2.2-a-iv
```{r}
library(ROCR)
roc.pred <- prediction(as.numeric(pred)-1, test.df$is_canceled)
roc.perf <- performance(roc.pred,"tpr","fpr")
plot(roc.perf,colorize=TRUE)
abline(a=0, b= 1)

```

### Part 2.2-a-v
```{r}
perf.auc <- performance(roc.pred, "auc")
print(paste("the AUC of the ROC curve is:",perf.auc@"y.values"))
```
### Part 2.3-a
```{r}
library(caret)
new.model <- rpart(is_canceled ~ ., data = select(train.df, -reservation_status, -country, -agent, -company, -reservation_status_date), method = "class", control=rpart.control(cp=0.0))
new.pred <- predict(new.model, test.df, type = "class")
cmx<-confusionMatrix(new.pred, as.factor(test.df$is_canceled), positive='1')
cat("Before pruning:\n  Accuracy:",round(as.double(cmx$overall["Accuracy"]),3),"\n  Error:",round(1-as.double(cmx$overall["Accuracy"]),3),"\n  Balanced Accuracy:",round(as.double(cmx$byClass["Balanced Accuracy"]),3),"\n  Specificity:",round(as.double(cmx$byClass["Specificity"]),3),"\n  Sensitivity:",round(as.double(cmx$byClass["Sensitivity"]),3),"\n  Precision:",round(as.double(cmx$byClass["Pos Pred Value"]),3))
```
### Part 2.3-b
```{r}
min.xerror <- which.min(new.model$cptable[,"xerror"])
cpx <- new.model$cptable[min.xerror,"CP"]
print(paste("Prune point occurs at a complexity of",6.03364e-05," At this complexity, xerror is",round(new.model$cptable[min.xerror,"xerror"],5)))
pruned.model <- prune(new.model, cp=cpx)
```
### Part 2.3-c
```{r}
pruned.pred <- predict(pruned.model, test.df, type = "class")
cmx<-confusionMatrix(pruned.pred, as.factor(test.df$is_canceled), positive='1')
cat("Before pruning:\n  Accuracy:",round(as.double(cmx$overall["Accuracy"]),3),"\n  Error:",round(1-as.double(cmx$overall["Accuracy"]),3),"\n  Balanced Accuracy:",round(as.double(cmx$byClass["Balanced Accuracy"]),3),"\n  Specificity:",round(as.double(cmx$byClass["Specificity"]),3),"\n  Sensitivity:",round(as.double(cmx$byClass["Sensitivity"]),3),"\n  Precision:",round(as.double(cmx$byClass["Pos Pred Value"]),3))
```
### Part 2.3-d
#### The pruned tree generalizes better.
### Part 2.3-e
#### Model in Problem 2.3(b) generalizes the best