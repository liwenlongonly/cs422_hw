---
  title: "Homework 7"
output: 
  html_notebook:
  toc: yes
  toc_float: yes
author: Wenlong Li
---
  
```{r}
library(keras)
library(dplyr)
library(caret)

rm(list=ls())

# Set working directory as needed
setwd("./")

df <- read.csv("activity-small.csv")

# Seed the PRNG
set.seed(1122)
df <- df[sample(nrow(df)), ] # Shuffle, as all of the data in the .csv file
                             # is ordered by label!  This will cause problems
                             # if we do not shuffle as the validation split
                             # may not include observations of class 3 (the
                             # class that occurs at the end).  The validation_
                             # split parameter samples from the end of the
                             # training set.

# Scale the dataset.  Copy this block of code as is and use it; we will get
# into the detail of why we scale.  We will scale our dataset so all of the
# predictors have a mean of 0 and standard deviation of 1.  Scale test and
# training splits independently!

indx <- sample(1:nrow(df), 0.20*nrow(df))
test.df  <- df[indx, ]
train.df <- df[-indx, ]

label.test <- test.df$label
test.df$label <- NULL
test.df <- as.data.frame(scale(test.df))
test.df$label <- label.test
rm(label.test)

label.train <- train.df$label
train.df$label <- NULL
train.df <- as.data.frame(scale(train.df))
train.df$label <- label.train
rm(label.train)
rm(indx)

```
# --- Your code goes below ---

```{r}

create_model <- function(){
  model <- keras_model_sequential() %>%
  layer_dense(units = 8, activation="relu", input_shape=c(3)) %>%
  layer_dense(units = 4, activation="softmax")
  
  model # Print the summary of the model.

  model %>% 
  compile(loss = "categorical_crossentropy", 
          optimizer="adam", 
          metrics=c("accuracy"))
  return(model)
}

X_train <- select(train.df, -label)
y_train <- train.df$label
y_train.ohe <- to_categorical(y_train)

X_test <- select(test.df, -label)
y_test <- test.df$label
y_test.ohe <- to_categorical(test.df$label)

model <- NULL
model <- create_model()

model %>% fit(
  data.matrix(X_train), 
  y_train.ohe,
  epochs=100,
  batch_size=1,
  validation_split=0.20
)

model %>% evaluate(as.matrix(X_test), y_test.ohe)
pred.prob <- predict(model, as.matrix(X_test))
pred.class <- apply(pred.prob, 1, function(x) which.max(x)-1)
confusionMatrix(as.factor(pred.class), as.factor(y_test))

```



