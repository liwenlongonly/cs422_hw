---
title: "CS 422"
output: 
  html_notebook:
    toc: yes
    toc_float: yes
author: Wenlong Li
---
### Part 2.1
```{r}
library(caret)
library(dplyr)
library(randomForest)
setwd("./")
df <- read.csv("hotel_bookings.csv", sep = ',',header = T)
df$is_canceled <- as.factor(df$is_canceled)

set.seed(1122)
index <- sample(1:nrow(df), 0.9*dim(df)[1])
train.df <- df[index,]
test.df <- df[-index,]

train.new.df <- select(train.df, -reservation_status, -country, -agent, -company, -reservation_status_date)

result <- matrix(nrow = 0, ncol = 6)
colnames(result) <- c("ntree","mtry","oobError","balancedAccuracy","specificity","sensitivity");

mtry = floor(sqrt(ncol(train.new.df)-1))

ntrees <- c(250, 500, 750)
mtrys <- c(mtry, mtry+1, mtry+2)
for(i in ntrees){
  for(j in mtrys){
    model <- randomForest(is_canceled ~ ., data=train.new.df,ntree=i, mtry=j, na.action = na.omit)
    oobError <- mean(model$err.rate)
    pred <- predict(model, test.df, type="class")
    cm <- confusionMatrix(pred, as.factor(test.df$is_canceled), positive='1')
    balancedAccuracy = as.double(cm$byClass["Balanced Accuracy"])
    specificity = as.double(cm$byClass["Specificity"])
    sensitivity = as.double(cm$byClass["Sensitivity"])
    result <- rbind(result, c(i, j, oobError, balancedAccuracy, specificity, sensitivity))
  }
}
print(result)

```
### Part 2.1-i
#### model of ntree = 500 and mtry = 6
### Part 2.1-ii
#### model of ntree = 750 and mtry = 7
### Part 2.1-iii
#### No, Mainly because of the problem of the verification set, the verification data of OOB Error is verification data for a certain decision tree, but it may be training data for another decision tree, so OOB Error cannot reflect the generalization ability of this model. From the output The data shows that the smallest OOB Error model has overfitting problems, so the cross-validation of OOB Error and confusion matrix cannot be used as the same evaluation indicator